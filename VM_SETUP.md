# ğŸ–¥ï¸ Configuration VM pour l'entraÃ®nement du modÃ¨le

## ğŸ“Š Comparaison des VMs

### VM Kali Linux (RecommandÃ©e âœ…)
**Avantages :**
- âœ… Meilleur support pour ML/AI (CUDA, PyTorch)
- âœ… Outils Linux optimisÃ©s pour le traitement
- âœ… Meilleure gestion de la mÃ©moire
- âœ… Plus facile pour installer les dÃ©pendances ML
- âœ… Support natif pour les GPU (si disponible)

**InconvÃ©nients :**
- Interface en ligne de commande (mais on peut installer un GUI)

### VM Windows 10
**Avantages :**
- Interface graphique familiÃ¨re
- Facile Ã  utiliser

**InconvÃ©nients :**
- âŒ Moins optimal pour ML/AI
- âŒ Installation CUDA plus complexe
- âŒ Performance gÃ©nÃ©ralement infÃ©rieure

## âš ï¸ Limitation importante : 4GB RAM

**ProblÃ¨me** : 4GB de RAM est **trÃ¨s limitÃ©** pour entraÃ®ner un modÃ¨le LLM de 7B (Mistral/Llama).

### Options avec 4GB RAM :

#### Option 1 : ModÃ¨le plus petit (RecommandÃ©)
- Utiliser **Mistral 7B** avec **LoRA** + **4-bit quantization**
- NÃ©cessite environ **6-8GB RAM** (limite avec 4GB)
- **Solution** : Utiliser un modÃ¨le plus petit comme **TinyLlama 1.1B** ou **Phi-2 (2.7B)**

#### Option 2 : Cloud / Colab (Alternative)
- Utiliser **Google Colab** (gratuit, GPU disponible)
- Ou **Kaggle Notebooks** (gratuit, GPU)
- Ou **Hugging Face Spaces** (gratuit, GPU limitÃ©)

#### Option 3 : Fine-tuning trÃ¨s lÃ©ger
- Utiliser **LoRA** avec paramÃ¨tres trÃ¨s rÃ©duits
- Batch size = 1
- Gradient accumulation
- Risque d'erreurs mÃ©moire

## ğŸ¯ Recommandation

### Pour commencer (POC) :
1. **Utilise Kali Linux** pour l'environnement
2. **Commence avec un modÃ¨le plus petit** :
   - **TinyLlama 1.1B** (nÃ©cessite ~2-3GB RAM)
   - Ou **Phi-2 (2.7B)** (nÃ©cessite ~4-5GB RAM)
3. **Alternative** : Utilise **Google Colab** pour l'entraÃ®nement (gratuit, GPU)

### Pour la production (plus tard) :
- Upgrade RAM Ã  **16GB minimum** (idÃ©alement 32GB)
- Ou utilise un service cloud (AWS, GCP, Azure)
- Ou utilise un GPU dÃ©diÃ©

## ğŸ“‹ Plan d'action

### Ã‰tape 1 : Choisir la VM
âœ… **Kali Linux** (recommandÃ©)

### Ã‰tape 2 : PrÃ©parer l'environnement sur Kali
```bash
# Installer Python 3.10+
sudo apt update
sudo apt install python3.10 python3-pip git

# Cloner le projet depuis GitHub
git clone https://github.com/Natacha-K-Cyber/tchad-langues-ai.git
cd tchad-langues-ai

# CrÃ©er environnement virtuel
python3 -m venv venv
source venv/bin/activate

# Installer dÃ©pendances (version allÃ©gÃ©e pour 4GB RAM)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install transformers datasets accelerate peft bitsandbytes
pip install streamlit pandas pyyaml
```

### Ã‰tape 3 : Choisir le modÃ¨le
- **TinyLlama 1.1B** : https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0
- **Phi-2** : https://huggingface.co/microsoft/phi-2

### Ã‰tape 4 : Alternative Cloud (RecommandÃ© pour POC)
- **Google Colab** : https://colab.research.google.com/
  - GPU gratuit (T4)
  - 12GB RAM
  - Parfait pour tester l'entraÃ®nement

## ğŸ”§ Configuration recommandÃ©e pour 4GB RAM

```yaml
model:
  base_model: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"  # Plus petit
  use_quantization: true  # 4-bit obligatoire
  use_lora: true
  lora_r: 8  # RÃ©duit (au lieu de 16)
  lora_alpha: 16  # RÃ©duit
  
training:
  per_device_train_batch_size: 1  # Minimum
  gradient_accumulation_steps: 8  # Pour simuler batch_size=8
  max_length: 256  # RÃ©duit (au lieu de 512)
```

## ğŸ’¡ Suggestion finale

**Pour le POC** : Utilise **Google Colab** pour l'entraÃ®nement
- Gratuit
- GPU disponible
- Pas de limitation RAM
- Facile Ã  partager

**Pour la VM** : Utilise **Kali Linux** pour :
- Le dÃ©veloppement de l'application
- Le traitement des donnÃ©es
- Les tests locaux

## ğŸ“ Prochaines Ã©tapes

1. âœ… Pousser le code sur GitHub
2. ğŸ”„ Cloner sur la VM Kali
3. ğŸ”„ Installer l'environnement
4. ğŸ”„ Tester avec un petit modÃ¨le
5. ğŸ”„ Ou utiliser Colab pour l'entraÃ®nement

